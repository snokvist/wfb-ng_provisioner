[common]
link_domain = 'auto_$(tr -dc 0-9 < /dev/urandom | head -c8)'
wifi_channel = 165 # 165 -- radio channel @5825 MHz, range: 5815â€“5835 MHz, width 20MHz
                       # see https://en.wikipedia.org/wiki/List_of_WLAN_channels for reference

wifi_region = 'US'     # Your country for CRDA (use BO or GY if you want max tx power)

wifi_txpower = { 'wlan0': None, 'wlan1': None,'wlan2': None }


[cluster]

nodes = {
          # required host attrs: 'wlans'
          # optional host attrs (will override defaults):
          #           'ssh', 'server_address', 'wifi_txpower',
          #           'wifi_channel', 'ssh_user', 'ssh_port', 'ssh_key'
          #           'custom_init_script'
          #
          # If ssh_user or ssh_port is set to None then node will not be automatically initialized in ssh mode.
          # If ssh_key is None, then ssh_agent will be used.

          # Local cards (use driver-default txpower settings):
          '127.0.0.1': { 'wlans': ['wlan1','wlan2','wlan0'], 'wifi_txpower': {'wlan0': None, 'wlan1': None, 'wlan2': None, }, 'server_address': '127.0.0.1' }

          # Remote cards:
          #'192.168.1.123' : { 'wlans': ['wlan0', 'wlan1'], 'wifi_txpower': 'off'},    # rx-only node
          #'192.168.1.155' : { 'wlans': ['wlan0', 'wlan1']},     # rx/tx node
        }

# Cluster init can be auto (--cluster ssh) or manual (--cluster manual)
# In second case you need to generate node setup scripts via (--gen-init)
# and run them on cluster nodes yourself

ssh_user = 'root'
ssh_port = 22
ssh_key = None            # Path to ssh private key. If None then it will try to use ssh-agent
custom_init_script = None # Do some custom command inside of node init script before wfb-ng start
                          # You can specify any bash snippet here

server_address = '192.168.1.49'     # Set to IP address which is reachable from all cluster nodes
                          # For local cards need to override it to 127.0.0.1 in the node attributes!

base_port_server = 10000  # UDP ports allocated on server
base_port_node = 11000    # UDP ports allocated on nodes


[gs]
streams = [{'name': 'video',   'stream_rx': 0x00, 'stream_tx': None, 'service_type': 'udp_direct_rx',  'profiles': ['base', 'gs_base', 'video', 'gs_video']},
                      {'name': 'tunnel',  'stream_rx': 0x20, 'stream_tx': 0xa0, 'service_type': 'tunnel',  'profiles': ['base', 'gs_base', 'tunnel', 'gs_tunnel']}
           ]

stats_port = 8003  # used by wfb-cli
api_port = 8103    # public JSON API
link_domain = "default"

[gs_bind]
streams = [{'name': 'bind_tunnel',  'stream_rx': 0x7f, 'stream_tx': 0xff, 'service_type': 'tunnel',  'profiles': ['base', 'bind_base', 'tunnel', 'gs_bind_tunnel']}]
stats_port = 8099
api_port = 8199
link_domain = "drone_bind"
bandwidth = 20

[gs_bind_tunnel]
fwmark = 30  #  traffic shaper label
ifname = 'gs-bind'
ifaddr = '10.5.99.1/24'
default_route = False

[tunnel]
bandwidth = 20

[gs_mavlink]
peer = 'connect://127.0.0.1:14550'  # mavlink connection to QGC

[gs_video]
bandwidth = 20
peer = 'connect://127.0.0.1:5600'  # outgoing connection for
                                   # video sink (QGroundControl on GS)
                                   #
